{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Finders and Minimizers in Python\n",
    "### by [Richard W. Evans](https://sites.google.com/site/rickecon/), May 2017\n",
    "\n",
    "The code in this Jupyter notebook was written using Python 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General characterization of maximization/minimization problem\n",
    "Root finders and minimizers are the two key tools for solving numerical optimization problems. We will define the general formulation of an optimization problem as a minimization problem in the following way,\n",
    "\n",
    "$$ \\min_{x}\\: f\\left(x,z|\\theta\\right) \\quad\\text{s.t}\\quad g(x,z|\\theta)\\geq 0 \\quad\\text{and}\\quad h(x) = 0 $$\n",
    "\n",
    "where $f$ is a system of potentially nonlinear equations that are a function of the vectors of (potentially dynamic)  variables $x$ and $z$ and parameter vector $\\theta$, subject to the vector of inequality constraints $g$ and the vector of equality constraints $h$.\n",
    "\n",
    "A computational algorithm that searches for the value of $x$ that minimizes the problem above is called a **minimizer**. Sometimes the solution to the minimization problem above can be written as a system of equations in $x$.\n",
    "\n",
    "$$ \\hat{x} = x: \\quad \\phi(x|z,\\theta) = 0 $$\n",
    "\n",
    "The maximization problem can be reduced to this system of characterizing equations when the inequality constraints can be shown to never bind (interior solution). A computational algorithm that searches for the value $\\hat{x}$ that sets the value of each equation in the system $\\phi(x|z)$ to 0 is called a **root finder**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Root Finders\n",
    "Suppose the solution to a system of $N$ nonlinear equations $\\phi(x|z,\\theta)=0$ is the $N\\times 1$ vector $\\hat{x}$. \n",
    "\n",
    "\n",
    "### 2.1. Univariate root finders\n",
    "Suppose that $x$ is a scalar such that the system of equations is one equation $\\phi(x|\\theta)=0$ and one unknown $x$. Let's assume the simple cubic polynomial functional form.\n",
    "\n",
    "$$\\phi(x|\\theta)= x^3 + x + \\theta $$\n",
    "\n",
    "The roots of this function are all the values of $x$ such that $\\phi(x|\\theta)=0$, or rather $x^3 + x + \\theta$. We first define a Python function `cubic_pol()` that takes as inputs a value for $x$ and a value for $\\theta$ and returns the value of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phi_pol(xvals, theta):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function returns the value phi(x,theta) given x and theta,\n",
    "    where phi(x,theta) = (x ** 3) + x + theta\n",
    "    --------------------------------------------------------------------\n",
    "    INPUTS:\n",
    "    xvals = scalar or (N,) vector, value or values for x\n",
    "    args  = length 1 tuple, (theta)\n",
    "    \n",
    "    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None\n",
    "    \n",
    "    OBJECTS CREATED WITHIN FUNCTION:\n",
    "    theta = scalar, constant in the phi function\n",
    "    phi   = scalar or (N,) vector, value of phi(xvals, theta)\n",
    "    \n",
    "    FILES CREATED BY THIS FUNCTION: None\n",
    "    \n",
    "    RETURNS: phi\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    phi = (xvals ** 3) + xvals + theta\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore this function $\\phi(x|\\theta)$ graphically by plotting it for a given value of $\\theta$ and for many values of $x$. The following plot is for $N=100$ values of $x$ between -10 and 10 and for $\\theta=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "# This next command is specifically for Jupyter Notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "theta = 10\n",
    "xmin = -10\n",
    "xmax = 10\n",
    "N = 100\n",
    "xvals = np.linspace(xmin, xmax, N)\n",
    "phi_vals = phi_pol(xvals, theta)\n",
    "\n",
    "# Plot the resulting phi values\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(xvals, phi_vals)\n",
    "minorLocator = MultipleLocator(1)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "plt.grid(b=True, which='major', color='0.65', linestyle='-')\n",
    "plt.title('Phi function for theta=10 and x=[-10,10]', fontsize=20)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$\\phi(x|\\theta=10)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, it looks like the function $\\phi(x|\\theta=10)$ has one root somewhere in the neighborhood of $x\\approx -2$. Plugging `x=2` into the function reveals that it is identically the root. So we know what the answer should be. Let's see how close the root finding algorithms get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `Scipy` library has a sub-library called `scipy.optimize`. The `scipy.optimize` sub-library has all of Python's most standard univariate and multivariate root finder algorithms as well as Python's most standard minimizer algorithms. Scrolling a little more than halfway down the main [`scipy.optimize` reference page](https://docs.scipy.org/doc/scipy/reference/optimize.html), we find the links to the documentation for the 5 univariate root finder algorithms in `scipy.optimize`. These are:\n",
    "\n",
    "* [`brentq()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq)\n",
    "* [`brenth()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brenth.html#scipy.optimize.brenth)\n",
    "* [`ridder()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.ridder.html#scipy.optimize.ridder)\n",
    "* [`bisect()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.bisect.html#scipy.optimize.bisect)\n",
    "* [`newton()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton.html#scipy.optimize.newton)\n",
    "\n",
    "The first four univariate root finders require a known bracketing interval for the root. That is, the user must know that $\\hat{x}\\in[a, b]$. For the `newton()` method, the bracketing interval is not required. We will solve for this root with the `bisect()` method and with the `newton()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "a =-5\n",
    "b = 0\n",
    "\n",
    "(xhat, result) = opt.bisect(phi_pol, a, b, args=(theta), full_output=True)\n",
    "\n",
    "print('xhat: ', xhat)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the Figure of the $\\phi(x|\\theta=10)$ function, the root for this function is very close to $\\hat{x}\\approx 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One caveat with the bisection method is that it will only find one root in the bracketing interval $[a,b]$. If the function has two roots in the interval, the `bisect()` method will only find one of them. This is true of all five univariate root finder methods as well as all minimizers and multivariate root finders in `scipy.optimize`. They will only return one root of minimum. Whether that root is unique or whether the minimum is a global min rather than a local min depends on how well the researcher understands the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `newton()` method uses a standard Newton-Raphson hill climbing (gradient descent) method to find the root of the function. Rather than needing to know the bracketing interval where the root exists, you must supply the function with an initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_init = 10.0\n",
    "\n",
    "xhat = opt.newton(phi_pol, x_init, args=(theta,))\n",
    "print(xhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note here is that the precision of the tolerance matters. That is, I can get a slightly different answer if I start the search from `x_init=-10`. In fact, when I start below the actual value I get the analytical solution $\\hat{x}=-2.0$. However, the difference between the two answers is extremely small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Multivariate root finders\n",
    "For our example of multivariate root finders, let's use the two characterizing equations for optimal lifetime savings from the 3-period-lived agent overlapping generations model with exogenous labor supply. In this case, the solution $x$ will be a $(2\\times 1)$ vector of savings for middle age $b_2$ and old age $b_3$ given interest rates ($r_2, r_3$) and wages ($w_1, w_2, w_3$) over the lifetime and utility function parameters ($\\beta, \\sigma$).\n",
    "\n",
    "$$ \\phi(b_2, b_3|r_2, r_3, w_1, w_2, w_3, \\beta, \\sigma) = 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\qquad\\:\\:\\:\\, (w_1 - b_2)^{-\\sigma} - \\beta(1 + r_2)([1 + r_2]b_2 + w_2 - b_3)^{-\\sigma} = 0 $$\n",
    "$$ \\Rightarrow ([1 + r_2]b_2 + w_2 - b_3)^{-\\sigma} - \\beta(1 + r_3)([1 + r_3]b_3 + w_3)^{-\\sigma} = 0 $$\n",
    "\n",
    "This is two equations and two unknowns ($b_2, b_3$). Everything other than the two savings levels is known in the two equations. Further, Inada conditions bound the solution for consumption strictly away from $c_t\\leq 0$, which means that the two equation system should be solvable using an unconstrained root finder for ($b_2, b_3$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first write some functions that compute the Euler errors shown above given the values for lifetime savings ($b_2, b_3$), interest rates ($r_2, r_3$), wages ($w_1, w_2, w_3$), and utility function parameters ($\\beta, \\sigma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ct(bt, btp1, rt, wt):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function returns the value of current period consumption given\n",
    "    b_t, b_{t+1}, r_t, and w_t.\n",
    "    --------------------------------------------------------------------\n",
    "    INPUTS:\n",
    "    bt   = scalar, current period savings\n",
    "    btp1 = scalar, savings for next period\n",
    "    rt   = scalar > 0, current period interest rate\n",
    "    wt   = scalar > 0, current period wage\n",
    "    \n",
    "    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None\n",
    "    \n",
    "    OBJECTS CREATED WITHIN FUNCTION:\n",
    "    ct = scalar, current period consumption\n",
    "    \n",
    "    FILES CREATED BY THIS FUNCTION: None\n",
    "    \n",
    "    RETURNS: ct\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    ct = (1 + rt) * bt + wt - btp1\n",
    "    \n",
    "    return ct\n",
    "\n",
    "\n",
    "def MU_stitch(ct, sigma):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    Generate marginal utility of consumption with CRRA consumption\n",
    "    utility and stitched function at lower bound such that the new\n",
    "    hybrid function is defined over all consumption on the real\n",
    "    line but the function has similar properties to the Inada condition.\n",
    "\n",
    "    u'(c) = c ** (-sigma) if c >= epsilon\n",
    "          = g'(c) = 2 * b2 * c + b1 if c < epsilon\n",
    "\n",
    "        such that g'(epsilon) = u'(epsilon)\n",
    "        and g''(epsilon) = u''(epsilon)\n",
    "\n",
    "        u(c) = (c ** (1 - sigma) - 1) / (1 - sigma)\n",
    "        g(c) = b2 * (c ** 2) + b1 * c + b0\n",
    "    --------------------------------------------------------------------\n",
    "    INPUTS:\n",
    "    ct    = scalar, current consumption\n",
    "    sigma = scalar >= 1, coefficient of relative risk aversion for CRRA\n",
    "            utility function: (c**(1-sigma) - 1) / (1 - sigma)\n",
    "\n",
    "    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None\n",
    "\n",
    "    OBJECTS CREATED WITHIN FUNCTION:\n",
    "    epsilon  = scalar > 0, positive value close to zero\n",
    "    c_cnstr  = boolean, =True if ct < epsilon\n",
    "    b1       = scalar, intercept value in linear marginal utility\n",
    "    b2       = scalar, slope coefficient in linear marginal utility\n",
    "    MU_c     = scalar, marginal utility of consumption\n",
    "    \n",
    "    FILES CREATED BY THIS FUNCTION: None\n",
    "\n",
    "    RETURNS: MU_c\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    epsilon = 0.0001\n",
    "    c_cnstr = ct < epsilon\n",
    "    if c_cnstr:\n",
    "        b2 = (-sigma * (epsilon ** (-sigma - 1))) / 2\n",
    "        b1 = (epsilon ** (-sigma)) - 2 * b2 * epsilon\n",
    "        MU_c = 2 * b2 * ct + b1\n",
    "    else:\n",
    "        MU_c = ct ** (-sigma)\n",
    "    \n",
    "    return MU_c\n",
    "\n",
    "\n",
    "def get_EulErrs(bvec, *args):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    INPUTS:\n",
    "    bvec = (2,) vector, values for lifetime savings (b2, b3)\n",
    "    args = length 7 tuple, (r2, r3, w1, w2, w3, beta, sigma)\n",
    "    \n",
    "    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:\n",
    "        get_ct()\n",
    "        MU_stitch()\n",
    "    \n",
    "    OBJECTS CREATED WITHIN FUNCTION:\n",
    "    r2    = scalar > 0, interest rate in period 2\n",
    "    r3    = scalar > 0, interest rate in period 3\n",
    "    w1    = scalar > 0, wage in period 1\n",
    "    w2    = scalar > 0, wage in period 2\n",
    "    w3    = scalar > 0, wage in period 3\n",
    "    beta  = scalar in (0, 1), discount factor\n",
    "    sigma = scalar >= 1, coefficient of relative risk aversion\n",
    "    c1    = scalar, consumption in period 1\n",
    "    c2    = scalar, consumption in period 2\n",
    "    c3    = scalar, consumption in period 3\n",
    "    MU_c1 = scalar > 0, marginal utility of consumption in period 1\n",
    "    MU_c2 = scalar > 0, marginal utility of consumption in period 2\n",
    "    MU_c3 = scalar > 0, marginal utility of consumption in period 3\n",
    "    err1  = scalar, Euler error for savings decision b2\n",
    "    err2  = scalar, Euler error for savings decision b3\n",
    "    err_vec = (2,) vector, Euler errors from two Euler equations\n",
    "    \n",
    "    FILES CREATED BY THIS FUNCTION: None\n",
    "    \n",
    "    RETURNS: err_vec\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    b2, b3 = bvec\n",
    "    r2, r3, w1, w2, w3, beta, sigma = args\n",
    "    c1 = get_ct(0.0, b2, 0.0, w1)\n",
    "    c2 = get_ct(b2, b3, r2, w2)\n",
    "    c3 = get_ct(b3, 0.0, r3, w3)\n",
    "    MU_c1 = MU_stitch(c1, sigma)\n",
    "    MU_c2 = MU_stitch(c2, sigma)\n",
    "    MU_c3 = MU_stitch(c3, sigma)\n",
    "    err1 = MU_c1 - beta * (1 + r2) * MU_c2\n",
    "    err2 = MU_c2 - beta * (1 + r3) * MU_c3\n",
    "    err_vec = np.array([err1, err2])\n",
    "    \n",
    "    return err_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run a multivariate root finder to try and find the solution to this problem. The function [`scipy.optimize.root()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html#scipy.optimize.root) contains all of the multivariate root finders in `SciPy`. Within `scipy.optimize.root()`, you can choose among 10 different methods of multivariate root finders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare parameter values and exogenous variable values\n",
    "beta = 0.96 ** (80 / 3)\n",
    "sigma = 2.1\n",
    "r2 = 0.6\n",
    "r3 = 0.7\n",
    "w1 = 0.5\n",
    "w2 = 0.5\n",
    "w3 = 0.5\n",
    "\n",
    "# Make initial guess for solution of savings values. Note that these\n",
    "# two guesses must be feasible and not violate c_t > 0 for all t\n",
    "b2_init = 0.05\n",
    "b3_init = 0.10\n",
    "b_init = np.array([b2_init, b3_init])\n",
    "b_args = (r2, r3, w1, w2, w3, beta, sigma)\n",
    "b_result = opt.root(get_EulErrs, b_init, args=(b_args))\n",
    "print(b_result)\n",
    "print('Roots: ', b_result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the multivariate minimizer above is stored as a Python dictionary named `b_result`. The elements of the dictionary include:\n",
    "\n",
    "* `fun`: the value of the error functions at the solution\n",
    "* `message`: a message about whether the solution converged\n",
    "* `nfev`: number of function evaluations until convergence\n",
    "* `success`: boolean that you want to equal `True`\n",
    "* `x`: the vector of roots of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimizers\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Unconstrained minimizers\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Constrained minimizers\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Notes\n",
    "The little advertised truth is that no root finder is guaranteed to find the right roots or any roots, and no minimizer is guaranteed to find the global minimum for any set of characterizing equations. More accurately, it is a rare and special case to find characterizing functions for which standard root finders and minimizers solve robustly. Press, et al (2007, pp. 442-443) highlight that with nonlinear multidimensional root finding problems,\n",
    "\n",
    "> \"...you can never be sure that the root is there at all until you have found it.... It cannot be overemphasized, however, how crucially success depends on having a good first guess for the solution,....\"\n",
    "\n",
    "Press, et al (2007, p. 473) also state,\n",
    "\n",
    "> \"We make an extreme, but wholly defensible statement: There are no good, general methods for solving systems of more than one nonlinear equation. Furthermore, it is not hard to see why (very likely) there never will be any good, general methods.\"\n",
    "\n",
    "Because initial values are so important to root finders and minimization problems, Judd (1998, p. 172) suggests running a minimization problem with a loose stopping rule on the vector of squared errors. Then one can use that solution as the initial guess for the root finder.\n",
    "\n",
    "Because root finding and minimization is so difficult, we take great care to report the errors and optimization output in our code. One must show not only that the minimizer or root finder stopped iterating, but also that the errors in the characterizing equations are arbitrarily small. One can also perform robustness tests using varying initial values to provide evidence that the solution is unique in the neighborhood of the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* Judd, Kenneth L., *Numerical Methods in Economics*, MIT Press (1998).\n",
    "* Press, William H., Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery, *Numerical Recipes: The Art of Scientific Computing*, 3rd edition, Cambridge University Press (2007)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
